{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18eed6b8",
   "metadata": {},
   "source": [
    "# Anime Recommended System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b15286",
   "metadata": {},
   "source": [
    "## Team member\n",
    "  - Nguyễn Quốc Bảo - 19133002\n",
    "  - Võ Hoàng Khả Diệu - 19133014\n",
    "  \n",
    "  This notebook explains how to use the [Anime Datasets]() to build a movie recommender using [collaborative filtering](https://en.wikipedia.org/wiki/Recommender_system#Collaborative_filtering) with [Spark's Alternating Least Saqures](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.recommendation.ALS.html) implementation. It is organised in two parts. The first one is about getting and parsing movies and ratings data into Spark RDDs. The second is about building and using the recommender and persisting it for later use in our on-line recommender system. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6c4c6d",
   "metadata": {},
   "source": [
    "## Getting and processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6542af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col,isnan, when, count\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d070782b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Anime recommendation\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "262457ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7613bb7",
   "metadata": {},
   "source": [
    "### Loading and parsing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35247c14",
   "metadata": {},
   "source": [
    "Now we are ready to read in each of the files and create an RDD consisting of parsed lines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea023ba",
   "metadata": {},
   "source": [
    "Each line in the rating_change dataset (`rating_change.csv`) is formatted as:  \n",
    "\n",
    "`user_id, anime_id, rating` \n",
    "\n",
    "(The `rating_change.csv` was handled and processed data from `rating.csv` at EDA part.)\n",
    "\n",
    "Each line in the animes (`anime.csv`) dataset is formatted as:  \n",
    "\n",
    "`anime_id, name, genre`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "727be259",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = os.path.join('../data')\n",
    "rating_file_path = os.path.join(datasets_path, 'rating_change.csv');\n",
    "rating_raw_RDD = sc.textFile(rating_file_path)\n",
    "anime_file_path = os.path.join(datasets_path, 'anime.csv')\n",
    "anime_raw_RDD = sc.textFile(anime_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da788090",
   "metadata": {},
   "source": [
    "So let's load the raw ratings data. We need to filter out the header, included in each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4edaafe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_data_raw_header = rating_raw_RDD.take(1)[0]\n",
    "anime_data_raw_header = anime_raw_RDD.take(1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd8a44",
   "metadata": {},
   "source": [
    "Now we can parse the raw data into a new RDD.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78b21ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_RDD = rating_raw_RDD.filter(lambda line: line!=rating_data_raw_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]), int(tokens[1]), int(tokens[2]))).cache()\n",
    "anime_title_RDD = anime_raw_RDD.filter(lambda line: line!=anime_data_raw_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda x: (int(x[0]), x[1])).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c0a01c",
   "metadata": {},
   "source": [
    "Count and first 5 rows in each RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46168223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5868892"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_RDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2c91a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 8074, 5), (1, 11617, 5), (1, 11757, 5), (1, 15451, 5), (2, 11771, 5)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_RDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "352c5a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12294"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_title_RDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d07f92c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32281, 'Kimi no Na wa.'),\n",
       " (5114, 'Fullmetal Alchemist: Brotherhood'),\n",
       " (28977, 'Gintama°'),\n",
       " (9253, 'Steins;Gate'),\n",
       " (9969, 'Gintama&#039;')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_title_RDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9109bdd1",
   "metadata": {},
   "source": [
    "Create dataframe from rdd for process recommendation system by spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0d5e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = spark.createDataFrame(data = rating_RDD, schema = [\"user_id\", \"anime_id\", \"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7bab5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+\n",
      "|user_id|anime_id|rating|\n",
      "+-------+--------+------+\n",
      "|      1|    8074|     5|\n",
      "|      1|   11617|     5|\n",
      "|      1|   11757|     5|\n",
      "|      1|   15451|     5|\n",
      "|      2|   11771|     5|\n",
      "+-------+--------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d5a012",
   "metadata": {},
   "outputs": [],
   "source": [
    "animes_df = spark.createDataFrame(data = anime_title_RDD, sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742c73bd",
   "metadata": {},
   "source": [
    "## Building and using the Recommended system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e78697",
   "metadata": {},
   "source": [
    "### Collaborative Filtering - ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5083a08e",
   "metadata": {},
   "source": [
    "Split rating data into 3 parts: Training, Validation and Testing with radio 6:2:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f2c4ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, validation, testing) = ratings_df.randomSplit([0.6, 0.2, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6dfeb0",
   "metadata": {},
   "source": [
    "#### Build & Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9fef05",
   "metadata": {},
   "source": [
    "Now we will proceed training phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4cb932",
   "metadata": {},
   "source": [
    "In training phrase, we will tuning parameters to choose the best model with Root Mean Squared Error (RMSE) is lowest possible.\n",
    "\n",
    "The parameters we used in this model: `ranks`, `maxIters`, `regParams`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba7b9486",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [8, 12]\n",
    "maxIters = [5, 10]\n",
    "regParams = [0.1, 0.01]\n",
    "bestParams = [-1, -1, -1]\n",
    "min_error = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af260e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execute time 0:01:24.056598\n",
      "Rank: 8, maxIter: 5, regParam: 0.1, RMSE: 0.9495164208810919\n",
      "Execute time 0:01:01.960883\n",
      "Rank: 8, maxIter: 5, regParam: 0.01, RMSE: 0.9835134803838274\n",
      "Execute time 0:01:13.352696\n",
      "Rank: 8, maxIter: 10, regParam: 0.1, RMSE: 0.9454070515172769\n",
      "Execute time 0:01:09.533617\n",
      "Rank: 8, maxIter: 10, regParam: 0.01, RMSE: 0.9849855122987078\n",
      "Execute time 0:01:08.960076\n",
      "Rank: 12, maxIter: 5, regParam: 0.1, RMSE: 0.9561809928480054\n",
      "Execute time 0:01:04.636614\n",
      "Rank: 12, maxIter: 5, regParam: 0.01, RMSE: 1.003703459426759\n",
      "Execute time 0:01:16.951480\n",
      "Rank: 12, maxIter: 10, regParam: 0.1, RMSE: 0.9449057402086288\n",
      "Execute time 0:01:20.487655\n",
      "Rank: 12, maxIter: 10, regParam: 0.01, RMSE: 1.0124456615310247\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "for rank in ranks:\n",
    "    for maxIter in maxIters:\n",
    "        for regParam in regParams:\n",
    "            start_time = datetime.now()\n",
    "            als = ALS(rank=rank, maxIter=maxIter, regParam=regParam, userCol=\"user_id\", itemCol=\"anime_id\", ratingCol=\"rating\")\n",
    "            model = als.fit(training)\n",
    "            model.setColdStartStrategy(\"drop\");\n",
    "            predictions = model.transform(validation)\n",
    "            evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                           predictionCol=\"prediction\")\n",
    "            rmse = evaluator.evaluate(predictions)\n",
    "            end_time = datetime.now()\n",
    "            if(rmse < min_error):\n",
    "                min_error = rmse\n",
    "                bestParams = [rank, maxIter, regParam]\n",
    "            print('Execute time {}'.format(end_time - start_time))\n",
    "            print('Rank: %s, maxIter: %s, regParam: %s, RMSE: %s' % (rank, maxIter, regParam, str(rmse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f8ff99",
   "metadata": {},
   "source": [
    "After tuning parameters, we got the best parameter for final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be8a275f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 10, 0.1]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestParams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17537412",
   "metadata": {},
   "source": [
    "The above values are respectively: `rank`, `maxIter` and `regParam`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770da5fc",
   "metadata": {},
   "source": [
    "#### Build & Test the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d878557",
   "metadata": {},
   "source": [
    "Use the best params to build the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cee2cb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execute time 0:00:45.731202\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "best_ALS = ALS(rank=bestParams[0], maxIter=bestParams[1], regParam=bestParams[2], userCol=\"user_id\", itemCol=\"anime_id\", ratingCol=\"rating\")\n",
    "best_model = als.fit(testing)\n",
    "end_time = datetime.now()\n",
    "print('Execute time {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4156013a",
   "metadata": {},
   "source": [
    "Now we will test the final model by our testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f72a7fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.6266904331154174\n"
     ]
    }
   ],
   "source": [
    "best_model.setColdStartStrategy(\"drop\");\n",
    "predictions = best_model.transform(testing)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                               predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9072aa49",
   "metadata": {},
   "source": [
    "Although we aim at building an on-line anime recommender, now that we know how to have our recommender model ready, we can give it a try providing some anime recommendations. This will help us coiding the recommending engine later on when building the web service, and will explain how to use the model in any other circumstances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1160bb6a",
   "metadata": {},
   "source": [
    "When using collaborative filtering, getting recommendations is not as simple as predicting for the new entries using a previously generated model. Instead, we need to train again the model but including the new user preferences in order to compare them with other users in the dataset. That is, the recommender needs to be trained every time we have new user ratings (although a single model can be used by multiple users of course!). This makes the process expensive, and it is one of the reasons why scalability is a problem (and Spark a solution!). Once we have our model trained, we can reuse it to obtain top recomendations for a given user or an individual rating for a particular movie. These are less costly operations than training the model itself.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f009a40e",
   "metadata": {},
   "source": [
    "#### Using the model for recommended system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6786514",
   "metadata": {},
   "source": [
    "Here, we will try to build a feature to recommend top 10 anime for a user (Example: user_id = 215)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "09a0ae70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_subset = ratings_df.where(ratings_df.user_id == 215)\n",
    "user_subset_recs = model.recommendForUserSubset(user_subset, 10)\n",
    "list_user_predictions = list(user_subset_recs.select('recommendations').toPandas()['recommendations'])\n",
    "user_prediction_rdd = sc.parallelize(list_user_predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0146aae4",
   "metadata": {},
   "source": [
    "`recommendForUserSubset` is a function of ALS is provided by package `ml`. It will take out the top 10 anime with the highest rating prediction and recommend to users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b684ab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join name of Anime into a new list\n",
    "list_complete_user_prediction = user_prediction_rdd.join(anime_title_RDD) \\\n",
    "    .map(lambda x: (x[0], x[1][1], x[1][0])) \\\n",
    "    .takeOrdered(10, key=lambda x: -x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e3e4a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change list to dataframe\n",
    "user_subset_recs_columns = [\"anime_id\",\"name\", \"rating\"]\n",
    "user_subset_recs_DF = spark.createDataFrame(data=list_complete_user_prediction, schema = user_subset_recs_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c95d9929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 anime recommended for userID is 215\n",
      "+--------+--------------------+-----------------+\n",
      "|anime_id|                name|           rating|\n",
      "+--------+--------------------+-----------------+\n",
      "|    7416|              Socket|6.557953357696533|\n",
      "|   32400|           KochinPa!|6.261995792388916|\n",
      "|   29978|                 001|6.244216442108154|\n",
      "|   29995|The Embryo Develo...|6.110090732574463|\n",
      "|    7485|      Urashima Tarou|6.042207717895508|\n",
      "|   22059|Kakumeiteki Broad...|5.638498306274414|\n",
      "|   22615|Kero Kero Keroppi...|5.526596546173096|\n",
      "|   22445|Hello Kitty no Ya...|5.526596546173096|\n",
      "|   17985|Kero Kero Keroppi...|5.526596546173096|\n",
      "|   22607|Ahiru no Pekkle n...|5.526596546173096|\n",
      "+--------+--------------------+-----------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Show output\n",
    "print(\"Top 10 anime recommended for userID is \" + str(user_subset.collect()[0][0]))\n",
    "print(user_subset_recs_DF.show(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e62aba",
   "metadata": {},
   "source": [
    "The above result is the top 10 anime with highest rating prediction for user 215"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218e98ec",
   "metadata": {},
   "source": [
    "#### Persisting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fadd0989",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('model') + \"/als_model\"\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27081ba2",
   "metadata": {},
   "source": [
    "### Content-base Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d95e16a",
   "metadata": {},
   "source": [
    "With Content-base, we will sklearn package for process and handle data and build model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9f18eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5547cd32",
   "metadata": {},
   "source": [
    "#### Loading and processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f12a2820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of item:  12017\n"
     ]
    }
   ],
   "source": [
    "#Reading anime file:\n",
    "animeDF = pd.read_csv(anime_file_path, sep=',', encoding='latin-1')\n",
    "animeDF.dropna(inplace=True)\n",
    "list_anime = animeDF[\"anime_id\"].to_numpy()\n",
    "#Get n_items\n",
    "n_items = animeDF.shape[0]\n",
    "print(\"Number of item: \", n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e38d1fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5868859, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading rating file:\n",
    "ratingDF = pd.read_csv(rating_file_path, sep=',', encoding='latin-1')\n",
    "ratingDF.dropna(inplace=True)\n",
    "ratingDF = ratingDF[ratingDF.anime_id.isin(animeDF.anime_id)]\n",
    "ratingDF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37adbe80",
   "metadata": {},
   "source": [
    "Split rating data into 2 parts: Training and Testing with radio 8:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33b0de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia tập train & tập test theo tỉ lệ 8 : 2\n",
    "train, test = train_test_split(ratingDF, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b8ab1c",
   "metadata": {},
   "source": [
    "#### Build Item profile use TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fc9df7",
   "metadata": {},
   "source": [
    "An important job in a content-based recommendation system is to build a profile for each item, i.e. a feature vector for each item. Because we are based on the genre of the movie to build the profile so we just need to care about the genre of movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bb8786",
   "metadata": {},
   "source": [
    "We will build feature vector for each item based on anime genre matrix and feature TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c670595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genre:  (12017, 43)\n"
     ]
    }
   ],
   "source": [
    "tf = TfidfVectorizer(analyzer=lambda s: (c for i in range(1,2)\n",
    "                                             for c in combinations(s.split(', '), r=i)))\n",
    "tfidf = tf.fit_transform(animeDF['genre']).toarray()\n",
    "print(\"Number of genre: \", tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3559281",
   "metadata": {},
   "source": [
    "After this step, each row of TF-IDF corresponds to the feature vector of a anime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7bfbd24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.29453722, 0.3158063 , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.262021  , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ca69f1",
   "metadata": {},
   "source": [
    "Next step, for each user, we need to find what animes that user has rated, and the value of those ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "260ff941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_rated_by_user(rate_matrix, user_id):\n",
    "    \"\"\"\n",
    "    return (items_index, scores)\n",
    "    \"\"\"\n",
    "    y = rate_matrix[:,0] # all users\n",
    "    # item indices rated by user_id\n",
    "    ids = np.where(y == user_id)[0]\n",
    "    item_ids = rate_matrix[ids,1]\n",
    "    items_index = get_items_index(item_ids)\n",
    "    #Rated score of user-item\n",
    "    scores = rate_matrix[ids, 2]\n",
    "    return (items_index, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "815ac8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_index(item_ids):\n",
    "    items_index = []\n",
    "    for i in item_ids:\n",
    "        item = np.where(list_anime == i)[0][0]\n",
    "        items_index.append(item)\n",
    "    return np.array(items_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18a2af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_index(list_users, user_id):\n",
    "    user_index = np.where(list_users == user_id)\n",
    "    return user_index[0][0]"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "2ed6200e",
   "metadata": {},
   "source": [
    "Countinues, we will build a loss function used Ridge Regression with linear model\n",
    "                            ![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fe16fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_users = train[\"user_id\"].unique()\n",
    "#list_users = ratingDF[\"user_id\"].unique()\n",
    "n_users = list_users.shape[0]\n",
    "rate_train = train.values\n",
    "d = tfidf.shape[1] # data dimension\n",
    "W = np.zeros((d, n_users), dtype=\"float32\")\n",
    "b = np.zeros((1, n_users), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295723e5",
   "metadata": {},
   "source": [
    "Now, we can find the Ridge Regression coefficients for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a5e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in list_users:\n",
    "    user_index = get_user_index(list_users, n)\n",
    "    items_index, scores = get_items_rated_by_user(rate_train, n)\n",
    "    clf = Ridge(alpha=0.01, fit_intercept  = True)\n",
    "    Xhat = tfidf[items_index, :]\n",
    "    clf.fit(Xhat, scores)\n",
    "    W[:, user_index] = clf.coef_\n",
    "    b[0, user_index] = clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a119e3c9",
   "metadata": {},
   "source": [
    "After calculating the W and b coefficients, the ratings for each item are predicted by calculating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "0551ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yhat = tfidf.dot(W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "5d48327e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.03281969, 3.66957689, 2.08579807, ..., 4.        , 4.        ,\n",
       "        4.        ],\n",
       "       [4.39710301, 5.14697979, 1.66693166, ..., 4.        , 4.        ,\n",
       "        4.        ],\n",
       "       [3.08352057, 4.86970859, 1.73364013, ..., 4.        , 4.        ,\n",
       "        4.        ],\n",
       "       ...,\n",
       "       [0.42809886, 4.04808235, 2.40285277, ..., 4.        , 4.        ,\n",
       "        4.        ],\n",
       "       [0.42809886, 4.04808235, 2.40285277, ..., 4.        , 4.        ,\n",
       "        4.        ],\n",
       "       [0.42809886, 4.04808235, 2.40285277, ..., 4.        , 4.        ,\n",
       "        4.        ]])"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729edf26",
   "metadata": {},
   "source": [
    "Here is an example with a user whose id is 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "e3fa6ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rated movies ids: [ 831 1620 3287   86 1413   14  971 2656 1013  365 4442   49   58 2132\n",
      "  342 3191 1834 4212  268  199 3219 4211  704 2922  186  841 1886  122\n",
      " 5876  803 1049 1142  118  723  687   72   40    1  138 1220  616  449\n",
      "  127 3031 1518  775 3593 2232 1686  643 1213 3342 1709 2035   43 6088\n",
      "  411 1445  339  288  101  206 1558 1067  702  708  374 1104]\n",
      "True ratings: [4 1 1 5 3 4 2 2 3 3 4 5 5 2 3 2 2 2 5 1 2 1 2 2 2 3 1 5 1 1 1 1 4 2 2 5 5\n",
      " 5 3 2 5 1 4 2 3 3 3 3 1 3 2 2 1 3 4 1 3 2 3 3 5 5 2 3 3 4 2 3]\n",
      "Predicted ratings: [5.58838434 0.78448587 2.9421338  4.00693145 3.21286943 3.70912148\n",
      " 2.12273656 2.26039409 3.66742369 3.14758545 3.29704275 3.9271322\n",
      " 4.27715149 2.14181856 3.08189739 1.9784583  2.26039409 2.26039409\n",
      " 3.80352568 1.31769112 3.15293865 2.26039409 2.56109614 2.58890921\n",
      " 1.77711876 2.57088987 1.00440152 4.27715149 2.52644507 1.46658511\n",
      " 0.90438322 2.35546655 2.08178209 2.17664239 2.26039409 4.27715149\n",
      " 4.87996999 3.42726398 3.31096893 1.81074647 2.26039409 2.31549383\n",
      " 3.31096893 2.25733091 2.31549383 2.75039065 3.15293865 3.66742369\n",
      " 2.73604022 2.56109614 2.40670424 2.10715315 0.99295276 1.833692\n",
      " 3.70912148 2.49605837 1.99373866 3.47519585 2.11971307 3.47519585\n",
      " 3.80352568 3.52552805 3.18206729 2.26039409 2.67915489 3.38261748\n",
      " 2.35546655 3.41588679]\n"
     ]
    }
   ],
   "source": [
    "#Example\n",
    "user_id = 3\n",
    "user_index = get_user_index(list_users, user_id)\n",
    "ids, scores = get_items_rated_by_user(rate_train, user_id)\n",
    "print('Rated movies ids:', ids)\n",
    "print('True ratings:', scores)\n",
    "print('Predicted ratings:', Yhat[ids, user_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b90ded",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcca76b",
   "metadata": {},
   "source": [
    "To evaluate the found model, we aslo use the Root Mean Squared Error (RMSE), which is the square root of the mean squared error. The error is calculated as the difference of true rating and predicted rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "01cb84f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(Yhat, rates, W, b, list_users):\n",
    "    se = 0\n",
    "    cnt = 0\n",
    "    for n in list_users:\n",
    "        user_index = get_user_index(list_users, n)\n",
    "        ids, scores_truth = get_items_rated_by_user(rates, n)\n",
    "        scores_pred = Yhat[ids, user_index]\n",
    "        e = scores_truth - scores_pred \n",
    "        se += (e*e).sum(axis = 0)\n",
    "        cnt += e.size \n",
    "    return math.sqrt(se/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "7b4a567a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training: 0.8018556525917064\n"
     ]
    }
   ],
   "source": [
    "list_users_train = train[\"user_id\"].unique()\n",
    "print('RMSE for training:', evaluate(Yhat, rate_train, W, b, list_users_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "5e932beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for test    : 1.7779041818414867\n"
     ]
    }
   ],
   "source": [
    "rate_test = test.values\n",
    "list_users_test = test[\"user_id\"].unique()\n",
    "print('RMSE for test    :', evaluate(Yhat, rate_test, W, b, list_users_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b049d9e",
   "metadata": {},
   "source": [
    "So, with the training set, the error is about 0.8 stars; with the test set, the error is a bit larger, about 1.77. We see that this result is not really good because we have simplified the model too much"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff4b5c2742f77f69a96d5e9ce5123ac3550243876c0a3bcae77163366795a70c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
