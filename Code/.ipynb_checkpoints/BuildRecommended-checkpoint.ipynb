{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18eed6b8",
   "metadata": {},
   "source": [
    "# Anime Recommended System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b15286",
   "metadata": {},
   "source": [
    "## Team member\n",
    "  - Nguyễn Quốc Bảo - 19133002\n",
    "  - Võ Hoàng Khả Diệu - 19133014\n",
    "  \n",
    "  This notebook explains how to use the [Anime Datasets]() to build a movie recommender using [collaborative filtering](https://en.wikipedia.org/wiki/Recommender_system#Collaborative_filtering) with [Spark's Alternating Least Saqures](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.recommendation.ALS.html) implementation. It is organised in two parts. The first one is about getting and parsing movies and ratings data into Spark RDDs. The second is about building and using the recommender and persisting it for later use in our on-line recommender system. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6c4c6d",
   "metadata": {},
   "source": [
    "## Getting and processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f6542af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, RegexTokenizer\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col,isnan, when, count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "eb8af78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo một sparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ALS recommendation spark session\") \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .config(\"spark.executor.memory\", \"25g\") \\\n",
    "    .config('spark.cores.max', '16') \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "#    .master('spark://192.168.1.171:7077') \\\n",
    "#    .config(\"spark.driver.host\", \"192.168.1.171\") \\\n",
    "#    .config(\"spark.driver.port\", \"10027\") \\\n",
    "#    .config(\"spark.submit.deployMode\", \"cluster\") \\\n",
    "#    .config(\"spark.driver.bindAddress\", \"0.0.0.0\") \\\n",
    "#    .config(\"spark.dynamicAllocation.enabled\", False) \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "262457ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "727be259",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = os.path.join('../data')\n",
    "rating_file_path = os.path.join(datasets_path, 'rating.csv')\n",
    "rating_raw_RDD = sc.textFile(rating_file_path)\n",
    "anime_file_path = os.path.join(datasets_path, 'anime.csv')\n",
    "anime_raw_RDD = sc.textFile(anime_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4edaafe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_data_raw_header = rating_raw_RDD.take(1)[0]\n",
    "anime_data_raw_header = anime_raw_RDD.take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "78b21ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_RDD = rating_raw_RDD.filter(lambda line: line!=rating_data_raw_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]), int(tokens[1]), int(tokens[2]))).cache()#\n",
    "anime_title_RDD = anime_raw_RDD.filter(lambda line: line!=anime_data_raw_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda x: (int(x[0]), x[1])).cache()\n",
    "anime_genre_tf_idf_rdd = anime_raw_RDD.filter(lambda line: line != anime_data_raw_header) \\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda x: (int(x[0]), x[1], x[2])).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2c91a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 20, -1), (1, 24, -1), (1, 79, -1), (1, 226, -1), (1, 241, -1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_RDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d07f92c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32281, 'Kimi no Na wa.'),\n",
       " (5114, 'Fullmetal Alchemist: Brotherhood'),\n",
       " (28977, 'Gintama°'),\n",
       " (9253, 'Steins;Gate'),\n",
       " (9969, 'Gintama&#039;')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_title_RDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2fa2da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_rating(rating):\n",
    "    if(rating == 6):\n",
    "        return 1\n",
    "    if(rating == 7):\n",
    "        return 2\n",
    "    if(rating == 8):\n",
    "        return 3\n",
    "    if(rating == 9):\n",
    "        return 4\n",
    "    if(rating == 10):\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad15a540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test rating from 1 to 10\n",
    "#rating_RDD_data = rating_RDD.filter(lambda line: line!=rating_data_raw_header)\\\n",
    "#    .filter(lambda x: x[2] != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21de59be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test rating from 6 to 10\n",
    "rating_RDD_data = rating_RDD.filter(lambda line: line!=rating_data_raw_header)\\\n",
    "    .filter(lambda x: x[2] != -1 and x[2] != 1 and x[2] != 2 and x[2] != 3 and x[2] != 4 and x[2] != 5)\\\n",
    "    .map(lambda x: (int(x[0]), int(x[1]), int(change_rating(x[2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cd0fe1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 8074, 5),\n",
       " (1, 11617, 5),\n",
       " (1, 11757, 5),\n",
       " (1, 15451, 5),\n",
       " (2, 11771, 5),\n",
       " (3, 20, 3),\n",
       " (3, 154, 1),\n",
       " (3, 170, 4),\n",
       " (3, 199, 5),\n",
       " (3, 225, 4)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_RDD_data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80d3abf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5868892"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_RDD_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0d5e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe from rdd\n",
    "ratings_df = spark.createDataFrame(data = rating_RDD_data, schema = [\"user_id\", \"anime_id\", \"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e7bab5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+\n",
      "|user_id|anime_id|rating|\n",
      "+-------+--------+------+\n",
      "|      1|    8074|     5|\n",
      "|      1|   11617|     5|\n",
      "|      1|   11757|     5|\n",
      "|      1|   15451|     5|\n",
      "|      2|   11771|     5|\n",
      "+-------+--------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742c73bd",
   "metadata": {},
   "source": [
    "## Building and using the Recommended system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc67de53",
   "metadata": {},
   "source": [
    "### Content-base Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fab23b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed82f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7992b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ca17a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15e78697",
   "metadata": {},
   "source": [
    "### Collaborative Filtering - ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1463da85",
   "metadata": {},
   "source": [
    "#### Building and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f2c4ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia tập train & tập test theo tỉ lệ 8 : 2\n",
    "(training, testing) = ratings_df.randomSplit([0.8, 0.2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af260e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execute time 0:01:03.786310\n"
     ]
    }
   ],
   "source": [
    "# Xây dựng mô hình recommendation sử dụng thuật toán ALS trên tập dữ liệu huấn luyện\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "als = ALS(maxIter=10, regParam=0.1, userCol=\"user_id\", itemCol=\"anime_id\", ratingCol=\"rating\")\n",
    "model = als.fit(training)\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('Execute time {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f72a7fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.9385759774524401\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "model.setColdStartStrategy(\"drop\");\n",
    "predictions = model.transform(testing)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                               predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b84c50f",
   "metadata": {},
   "source": [
    "#### Using the model for recommended system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "09a0ae70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Recommended: top 10 movies for a user\n",
    "user_subset = ratings_df.where(ratings_df.user_id == 215)\n",
    "user_subset_recs = model.recommendForUserSubset(user_subset, 10)\n",
    "list_user_predictions = list(user_subset_recs.select('recommendations').toPandas()['recommendations'])\n",
    "user_prediction_rdd = sc.parallelize(list_user_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b684ab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join name of Anime into a new list\n",
    "list_complete_user_prediction = user_prediction_rdd.join(anime_title_RDD) \\\n",
    "    .map(lambda x: (x[0], x[1][1], x[1][0])) \\\n",
    "    .takeOrdered(10, key=lambda x: -x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e3e4a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change list to dataframe\n",
    "user_subset_recs_columns = [\"anime_id\",\"name\", \"rating\"]\n",
    "user_subset_recs_DF = spark.createDataFrame(data=list_complete_user_prediction, schema = user_subset_recs_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c95d9929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 anime recommended for userID is 215\n",
      "+--------+--------------------+-----------------+\n",
      "|anime_id|                name|           rating|\n",
      "+--------+--------------------+-----------------+\n",
      "|    7416|              Socket|6.557953357696533|\n",
      "|   32400|           KochinPa!|6.261995792388916|\n",
      "|   29978|                 001|6.244216442108154|\n",
      "|   29995|The Embryo Develo...|6.110090732574463|\n",
      "|    7485|      Urashima Tarou|6.042207717895508|\n",
      "|   22059|Kakumeiteki Broad...|5.638498306274414|\n",
      "|   22615|Kero Kero Keroppi...|5.526596546173096|\n",
      "|   22445|Hello Kitty no Ya...|5.526596546173096|\n",
      "|   17985|Kero Kero Keroppi...|5.526596546173096|\n",
      "|   22607|Ahiru no Pekkle n...|5.526596546173096|\n",
      "+--------+--------------------+-----------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Show output\n",
    "print(\"Top 10 anime recommended for userID is \" + str(user_subset.collect()[0][0]))\n",
    "print(user_subset_recs_DF.show(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218e98ec",
   "metadata": {},
   "source": [
    "#### Persisting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fadd0989",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('model') + \"/als_model\"\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f403fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "df55ca822cac8600970ddc952aa5519d3756106ef93b96d69fd5fdf417daf882"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
